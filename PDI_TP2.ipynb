{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PDI-TP2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juangross/cursoAM2021/blob/main/PDI_TP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqJjgWXpl2Qt"
      },
      "source": [
        "TP2)\n",
        "  La propuesta para esta actividad consiste en manipular independientemente la luminancia y la saturación de una imagen. Para ello convertimos cada pixel de la imagen del espacio RGB al espacio YIQ, luego alteramos los valores de Y (para cambiar la luminancia) y/o de IQ (para cambiar la saturación). Con los nuevos valores de YIQ, convertimos a RGB nuevamente y obtenemos una nueva imagen.\n",
        "\n",
        "**Observaciones**: para cada uno estos deben mostrar la imagen original vs el resultado de la modificación realizada a la imagen para un diferente rango de valores de prueba de Y e IQ.\n",
        "\n",
        "La segunda parte del TP2 consiste en utilizar algunos datasets 2D (pueden ser mapas de altitud, de temperatura, etc.) y “visualizarlos” con diferentes paletas, incluyendo la de niveles de gris y la arco iris. \n",
        "\n",
        "**Observaciones**: el objetivo es ver cómo con diferentes paletas de colores se pueden apreciar ciertos detalles de una imagen, sin necesidad de modificar el contenido de la misma.\n",
        "Les sugiero no utilizar imágenes de más de 1000 X 1000 pixeles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCXTR_KZPV-M"
      },
      "source": [
        "**Parte 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq3twaoolvXF",
        "outputId": "258eb7f2-4912-40c4-c98a-c80a99f83f2b"
      },
      "source": [
        "!git clone https://github.com/juangross/cAM"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cAM'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 37 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laBKoZXAl1iQ"
      },
      "source": [
        "Cargo imagen de prueba\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuXeToA4mYqY",
        "outputId": "c122456c-6e56-462d-b313-df8a6ddc7aa0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#import matplotlib.image as mpimg\n",
        "import imageio as img\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Import an image from directory:\n",
        "path=\"./cAM/imagenes/\"\n",
        "archi=\"patron_RGBCMYWK\"\n",
        "archo=\"output\"\n",
        "archo2=\"output2\"\n",
        "ext=\"png\"\n",
        "\n",
        "#formato actual\n",
        "\n",
        "print(\"leyendo archivo:\", f\"{path}{archi}.{ext}\")\n",
        "#input_image= mpimg.imread(f\"{archi}.{ext}\")  #lee con matplotlib\n",
        "input_image=img.imread(f\"{path}{archi}.{ext}\")      #lee con imageio\n",
        "\n",
        "#print (\"imagen de entrada\")\n",
        "#plt.subplot(1,2,1)\n",
        "#plt.imshow(input_image)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leyendo archivo: ./cAM/imagenes/patron_RGBCMYWK.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atzv7NUZajcv",
        "outputId": "7d7af342-67dc-4c67-a274-9b7291c9c9b3"
      },
      "source": [
        "input_tam=input_image.shape\n",
        "\n",
        "print(\"Dimensiones (X,Y,canales): \", input_tam)\n",
        "print(\"tipo de datos: \" , input_image.dtype)\n",
        "\n",
        "print(\"Datos en crudo: \")\n",
        "#input_image[:]\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones (X,Y,canales):  (4, 16, 3)\n",
            "tipo de datos:  uint8\n",
            "Datos en crudo: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "pEx0lOwXaMt9",
        "outputId": "caedb66e-2758-45c0-eb94-4a3695b789a0"
      },
      "source": [
        "#creo un array nuevo pero vacío usando numpy\n",
        "input_image_norm=np.zeros(input_tam, dtype=float)\n",
        "#normalizo los valores correspondientes a cada canal RGB. haciendo: <valor color pixel>/256\n",
        "#solamente se normaliza si el valor del color para ese canal es >0.\n",
        "\n",
        "#normalizo la imagen\n",
        "input_image_norm=1/255*input_image\n",
        "#print(input_image_norm)\n",
        "#print(input_image_norm.shape)\n",
        "\n",
        "#transformo a YIQ\n",
        "#me baso en esta explicación del producto matricial para hacer la conversión de bases\n",
        "#https://stackoverflow.com/questions/46990838/numpy-transforming-rgb-image-to-yiq-color-space\n",
        "YIQ_image=np.zeros(input_tam, dtype=float)\n",
        "YIQ_image_mod=np.zeros(input_tam, dtype=float)\n",
        "RGB2YIQ=np.array([[0.299,0.587,0.114],[0.595716,-0.274453,-0.321263],[0.211456,-0.522591,0.311135]], dtype=float)\n",
        "\n",
        "\n",
        "YIQ_image=np.dot(input_image_norm,RGB2YIQ.T.copy())\n",
        "#print(\"imagen YIQ\")\n",
        "#print(YIQ_image)\n",
        "\n",
        "#Genero los parámetros que voy a usar para alterar YIQ, en forma de una matriz, cada fila es una coordenada\n",
        "#[[Y],\n",
        "# [I],\n",
        "# [Q]]\n",
        "#K_YIQ=[-1,-1,1] #[Y,I,Q] coeficientes para alterar los canales\n",
        "#K_YIQ=np.array([[-1,-.75,-.5,-.25,0.,0.25,0.5,0.75,1,1.25,1.5,1.75,2.0],\n",
        "#                [-1,-.75,-.5,-.25,0.,0.25,0.5,0.75,1,1.25,1.5,1.75,2.0],\n",
        "#                [-1,-.75,-.5,-.25,0.,0.25,0.5,0.75,1,1.25,1.5,1.75,2.0]])\n",
        "K_YIQ=np.array([[-1,-.5,0.,0.5,1,1.5,2.0],\n",
        "                [-1,-.5,0.,0.5,1,1.5,2.0],\n",
        "                [-1,-.5,0.,0.5,1,1.5,2.0]])\n",
        "\n",
        "\n",
        "#copio la imagen \n",
        "YIQ_image_mod = YIQ_image\n",
        "\n",
        "#YIQ_image_mod[:,:,0] = YIQ_image[:,:,0]*K_YIQ[0]\n",
        "#YIQ_image_mod[:,:,1] = YIQ_image[:,:,1]*K_YIQ[1]\n",
        "#YIQ_image_mod[:,:,2] = YIQ_image[:,:,2]*K_YIQ[2]\n",
        "i=2\n",
        "\n",
        "YIQ_image_mod[:,:,0] = YIQ_image[:,:,0]*K_YIQ[0,i]\n",
        "#YIQ_image_mod[:,:,1] = YIQ_image[:,:,1]*K_YIQ[1,i]\n",
        "#YIQ_image_mod[:,:,2] = YIQ_image[:,:,2]*K_YIQ[2,i]\n",
        "\n",
        "\n",
        "#print(\"imagen YIQ alterada: \")\n",
        "#print(YIQ_image_mod)\n",
        "\n",
        "#YIQ -> RGB normalizado\n",
        "YIQ2RGB=np.array([[1,0.9663,0.6210 ],[1,-0.2721,-0.6474],[1,-1.1070,1.7046]], dtype=float)\n",
        "output_image_norm_RGB= np.dot(YIQ_image,YIQ2RGB.T.copy())\n",
        "#print(\"imagen RGB alterada\")\n",
        "#output_image_norm_RGB\n",
        "\n",
        "#desnormalizar RGB\n",
        "output_image=255*output_image_norm_RGB\n",
        "output_image=np.rint(output_image)  #redondeo a valores enteros\n",
        "output_image=np.clip(output_image,0,255) #recorto los valores que superen 255\n",
        "#output_image\n",
        "#print(output_image)\n",
        "\n",
        "\n",
        "#mostrar imagenes\n",
        "fig,axes=plt.subplots(1,2)\n",
        "#print (\"imagen de entrada\")\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(input_image)\n",
        "\n",
        "#imagen de salida\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(output_image.astype('uint8'))\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faadfe12990>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}