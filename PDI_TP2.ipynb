{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PDI-TP2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrn4N85v2f2pYiG0AL8BBY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juangross/cursoAM2021/blob/main/PDI_TP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqJjgWXpl2Qt"
      },
      "source": [
        "TP2)\n",
        "  La propuesta para esta actividad consiste en manipular independientemente la luminancia y la saturación de una imagen. Para ello convertimos cada pixel de la imagen del espacio RGB al espacio YIQ, luego alteramos los valores de Y (para cambiar la luminancia) y/o de IQ (para cambiar la saturación). Con los nuevos valores de YIQ, convertimos a RGB nuevamente y obtenemos una nueva imagen.\n",
        "\n",
        "**Observaciones**: para cada uno estos deben mostrar la imagen original vs el resultado de la modificación realizada a la imagen para un diferente rango de valores de prueba de Y e IQ.\n",
        "\n",
        "La segunda parte del TP2 consiste en utilizar algunos datasets 2D (pueden ser mapas de altitud, de temperatura, etc.) y “visualizarlos” con diferentes paletas, incluyendo la de niveles de gris y la arco iris. \n",
        "\n",
        "**Observaciones**: el objetivo es ver cómo con diferentes paletas de colores se pueden apreciar ciertos detalles de una imagen, sin necesidad de modificar el contenido de la misma.\n",
        "Les sugiero no utilizar imágenes de más de 1000 X 1000 pixeles\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq3twaoolvXF",
        "outputId": "4a14537f-f72f-464a-802b-06695ff28344"
      },
      "source": [
        "!git clone https://github.com/juangross/cAM"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cAM' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laBKoZXAl1iQ"
      },
      "source": [
        "Cargo imagen de prueba\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "uuXeToA4mYqY",
        "outputId": "2386db5c-f427-40d8-bbfe-0ff4d9e0ec11"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#import matplotlib.image as mpimg\n",
        "import imageio as img\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Import an image from directory:\n",
        "path=\"./cAM/imagenes/\"\n",
        "archi=\"patron_RGBCMYWK\"\n",
        "archo=\"output\"\n",
        "archo2=\"output2\"\n",
        "ext=\"png\"\n",
        "\n",
        "#formato actual\n",
        "\n",
        "print(\"leyendo archivo:\", f\"{path}{archi}.{ext}\")\n",
        "#input_image= mpimg.imread(f\"{archi}.{ext}\")  #lee con matplotlib\n",
        "input_image=img.imread(f\"{path}{archi}.{ext}\")      #lee con imageio\n",
        "\n",
        "print (\"imagen de entrada\")\n",
        "plt.imshow(input_image)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leyendo archivo: ./cAM/imagenes/patron_RGBCMYWK.png\n",
            "imagen de entrada\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc363f86950>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atzv7NUZajcv",
        "outputId": "d52fa927-d4a6-40f8-c384-274caefcda90"
      },
      "source": [
        "input_tam=input_image.shape\n",
        "\n",
        "print(\"Dimensiones (X,Y,canales): \", input_tam)\n",
        "print(\"tipo de datos: \" , input_image.dtype)\n",
        "\n",
        "print(\"Datos en crudo: \")\n",
        "input_image[:,:,:]\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones (X,Y,canales):  (4, 16, 3)\n",
            "tipo de datos:  uint8\n",
            "Datos en crudo: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[[255,   0,   0],\n",
              "        [255,   0,   0],\n",
              "        [  0, 255,   0],\n",
              "        [  0, 255,   0],\n",
              "        [  0,   0, 255],\n",
              "        [  0,   0, 255],\n",
              "        [  0, 255, 255],\n",
              "        [  0, 255, 255],\n",
              "        [255,   0, 255],\n",
              "        [255,   0, 255],\n",
              "        [255, 255,   0],\n",
              "        [255, 255,   0],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[255,   0,   0],\n",
              "        [255,   0,   0],\n",
              "        [  0, 255,   0],\n",
              "        [  0, 255,   0],\n",
              "        [  0,   0, 255],\n",
              "        [  0,   0, 255],\n",
              "        [  0, 255, 255],\n",
              "        [  0, 255, 255],\n",
              "        [255,   0, 255],\n",
              "        [255,   0, 255],\n",
              "        [255, 255,   0],\n",
              "        [255, 255,   0],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[255,   0,   0],\n",
              "        [255,   0,   0],\n",
              "        [  0, 255,   0],\n",
              "        [  0, 255,   0],\n",
              "        [  0,   0, 255],\n",
              "        [  0,   0, 255],\n",
              "        [  0, 255, 255],\n",
              "        [  0, 255, 255],\n",
              "        [255,   0, 255],\n",
              "        [255,   0, 255],\n",
              "        [255, 255,   0],\n",
              "        [255, 255,   0],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[255,   0,   0],\n",
              "        [255,   0,   0],\n",
              "        [  0, 255,   0],\n",
              "        [  0, 255,   0],\n",
              "        [  0,   0, 255],\n",
              "        [  0,   0, 255],\n",
              "        [  0, 255, 255],\n",
              "        [  0, 255, 255],\n",
              "        [255,   0, 255],\n",
              "        [255,   0, 255],\n",
              "        [255, 255,   0],\n",
              "        [255, 255,   0],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEx0lOwXaMt9",
        "outputId": "97b1eb6f-65b9-4581-fad6-e09686353e6f"
      },
      "source": [
        "#creo un array nuevo pero vacío usando numpy\n",
        "input_image_norm=np.zeros(input_tam, dtype=float)\n",
        "#normalizo los valores correspondientes a cada canal RGB. haciendo: <valor color pixel>/256\n",
        "#solamente se normaliza si el valor del color para ese canal es >0.\n",
        "\n",
        "#normalizo la imagen\n",
        "input_image_norm=1/255*input_image\n",
        "#print(input_image_norm)\n",
        "print(input_image_norm.shape)\n",
        "\n",
        "#transformo a YIQ\n",
        "YIQ_image_norm=np.zeros(input_tam, dtype=float)\n",
        "YIQ=np.array([[0.299,0.587,0.114],[0.595716,-0.274453,-0.321263],[0.211456,-0.522591,0.311135]], dtype=float)\n",
        "#print(YIQ.shape)\n",
        "a=np.array([[[1 , 0],[0 , 0],[0 , 1 ],[1 , 0],[0 , 0],[0 , 1 ]]])  # dos pixels , uno rojo y otro azul, normalizados\n",
        "print(a.shape)\n",
        "#a.transpose((1,0,2))\n",
        "\n",
        "#YIQ_image_norm=input_image_norm[,,:]* YIQ\n",
        "#print(YIQ.T)\n",
        "#YIQ_image_norm=np.dot(input_image_norm,YIQ.T.copy())\n",
        "#print (YIQ_image_norm)\n",
        "#for k in range (input_tam[2]):\n",
        "#  for j in range(input_tam[1]):\n",
        "#    for i in range(input_tam[0]):\n",
        "      #si el valor del pixel es >0 lo piso con el valor nuevo\n",
        "#        if(input_image_norm[i,j,k]):\n",
        "        #YIQ_image_norm[i,j,k]=np.matmul(input_image_norm[i,j,k],YIQ)\n",
        "#YIQ_image_norm=np.vdot(YIQ,input_image_norm)\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 16, 3)\n",
            "(1, 6, 2)\n"
          ]
        }
      ]
    }
  ]
}